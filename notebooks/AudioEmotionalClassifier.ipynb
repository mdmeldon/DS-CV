{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "AudioEmotionalClassifier.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaBIZYx2YfBB",
        "colab_type": "code",
        "outputId": "a2ac7630-f23f-4ed5-8472-2599778e5bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 1. Tell Git about yourself:\n",
        "from getpass import getpass\n",
        "u = input('Username: ') # Git username\n",
        "p = getpass('Password: ') # Git password"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Username: mdmeldon\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGuDbDbfYduo",
        "colab_type": "code",
        "outputId": "0c99946c-caa2-4a31-873f-0e734148ad96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# 2. Initialize Git, then Pull the Branch:\n",
        "! git init\n",
        "! git remote add origin https://$u:$p@github.com/mdmeldon/DS-CV.git \n",
        "! git pull origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 161, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 161 (delta 54), reused 125 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (161/161), 2.59 MiB | 2.50 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "From https://github.com/mdmeldon/DS-CV\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MlCEhp5ZQDi",
        "colab_type": "code",
        "outputId": "877a3da9-5725-498f-8f95-aab8a966cf5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 3. Run helper:\n",
        "! sh colab.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dvc==0.93.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/95/30391d897617a2029ce5a4451f397a44cf8a7428bf58854669fcf5b1c465/dvc-0.93.0-py2.py3-none-any.whl (332kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 2.8MB/s \n",
            "\u001b[?25hCollecting pydrive2==1.4.9\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/fe/d4e8085f898cccee1c545ea198139bd58a4e8fe597d2c64540c954561618/PyDrive2-1.4.9-py2.py3-none-any.whl\n",
            "Collecting catalyst\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/58/03dd689feee9089450d977b3be7b4579f097d236532afaeb64202d18fb72/catalyst-20.5.1-py2.py3-none-any.whl (362kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 7.8MB/s \n",
            "\u001b[?25hCollecting alchemy==20.4\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/d0/29085429e2f6203ee206a4aa93cb20cdafbdc2aa649d7b20de24eeb7fb69/alchemy-20.4-py2.py3-none-any.whl\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting funcy>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect<4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (2.1.0)\n",
            "Collecting gitpython>3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/f9/c315aa88e51fabdc08e91b333cfefb255aff04a2ee96d632c32cb19180c9/GitPython-3.1.3-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 18.5MB/s \n",
            "\u001b[?25hCollecting jsonpath-ng>=1.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/85/24/981fa76e1e415bcceb3a9741d5be04b32c10edd42d88f6783faa750b1239/jsonpath-ng-1.5.1.tar.gz\n",
            "Collecting tqdm<5,>=4.45.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hCollecting distro>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/b7/b3c4270a11414cb22c6352ebc7a83aaa3712043be29daa05018fd5a5c956/distro-1.5.0-py2.py3-none-any.whl\n",
            "Collecting treelib>=1.5.5\n",
            "  Downloading https://files.pythonhosted.org/packages/04/b0/2269c328abffbb63979f7143351a24a066776b87526d79956aea5018b80a/treelib-1.6.1.tar.gz\n",
            "Requirement already satisfied: humanize>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (0.5.1)\n",
            "Collecting grandalf==0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/54/f4/a0b6a4c6d616d0a838b2dd0bc7bf74d73e8e8cdc880bab7fdb5fdc3d0e06/grandalf-0.6-py3-none-any.whl\n",
            "Collecting voluptuous>=0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/3b/fe531688c0d9e057fccc0bc9430c0a3d4b90e0d2f015326e659c2944e328/voluptuous-0.11.7.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting configobj>=5.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\n",
            "Collecting dpath<3,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/60/3f/562b045ad2542ab1279bbc5a05a62511c1ea1d8b5987fb0a50ee78704621/dpath-2.0.1.tar.gz\n",
            "Collecting networkx<2.4,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 18.5MB/s \n",
            "\u001b[?25hCollecting zc.lockfile>=1.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl\n",
            "Collecting nanotime>=0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/54/6d5924f59cf671326e7809f4b3f70fa8df535d67e952ad0b6fea02f52faf/nanotime-0.5.2.tar.gz\n",
            "Collecting PyYAML<5.4,>=5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 30.2MB/s \n",
            "\u001b[?25hCollecting texttable>=0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/b1/8a1c659ce288bf771d5b1c7cae318ada466f73bd0e16df8d86f27a2a3ee7/texttable-1.6.2-py2.py3-none-any.whl\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting pygtrie==2.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/18/41/2e5cefc895a32d9ca0f3574bd0df09e53a697023579a93582bedc4eeac4d/pygtrie-2.3.2.tar.gz\n",
            "Collecting flatten-json>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a9/1e35abfc4726065f9692decb3c57cf379e5d5329befc6fa5a1ab835fffb8/flatten_json-0.1.7-py3-none-any.whl\n",
            "Collecting pathspec>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/d0/887c58853bd4b6ffc7aa9cdba4fc57d7b979b45888a6bd47e4568e1cf868/pathspec-0.8.0-py2.py3-none-any.whl\n",
            "Collecting flufl.lock>=3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/68/393c148df629f90a919de653ebb967a8bd8c83d07d2bc3150ca0faff3940/flufl.lock-3.2.tar.gz\n",
            "Collecting python-dateutil<2.8.1,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (46.4.0)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (20.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (2.23.0)\n",
            "Collecting ruamel.yaml>=0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/92/59af3e38227b9cc14520bf1e59516d99ceca53e3b8448094248171e9432b/ruamel.yaml-0.16.10-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from dvc==0.93.0) (0.4.8)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting ply>=3.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive2==1.4.9) (4.1.3)\n",
            "Collecting pyOpenSSL>=19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.7.12 in /usr/local/lib/python3.6/dist-packages (from pydrive2==1.4.9) (1.7.12)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.4)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.2.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n",
            "Collecting deprecation\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n",
            "Collecting crc32c>=1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/82/f60248c01a8a23ae07bd4c43d78d69b20ffe324311db3b0785e391aa09d2/crc32c-2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.5.0+cu101)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from jsonpath-ng>=1.5.1->dvc==0.93.0) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonpath-ng>=1.5.1->dvc==0.93.0) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from treelib>=1.5.5->dvc==0.93.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from grandalf==0.6->dvc==0.93.0) (2.4.7)\n",
            "Collecting atpublic\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/71/125eefdde54cf640eb2c22f868158fb0595fce1512c6c51201b105c44e63/atpublic-1.0.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.93.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.93.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.93.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->dvc==0.93.0) (1.24.3)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive2==1.4.9) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive2==1.4.9) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive2==1.4.9) (0.17.3)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (1.7.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.12->pydrive2==1.4.9) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.6.0.post3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.2.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.29.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.34.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.2.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyOpenSSL>=19.1.0->pydrive2==1.4.9) (1.14.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.12->pydrive2==1.4.9) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (1.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.1.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyOpenSSL>=19.1.0->pydrive2==1.4.9) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Building wheels for collected packages: funcy, jsonpath-ng, treelib, voluptuous, configobj, dpath, networkx, nanotime, PyYAML, pygtrie, flufl.lock, atpublic\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=2727abe0cd2adee58c7433fbeb8c168da6e54a881e3199cc52ad0a28aa332504\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "  Building wheel for jsonpath-ng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath-ng: filename=jsonpath_ng-1.5.1-cp36-none-any.whl size=23919 sha256=33b760affe937024ec43fb0b26d45f1d17cb138be81f78854769f6e985e862cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/e6/94/298d44da8cc99fca216343afc8d877348146d583beac99ec49\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-cp36-none-any.whl size=18370 sha256=165ebdf01a2704b0ede182e1e530c2a7a8f9351c215f58e3033d3f3d9fbd8a5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/1d/92/c50ec52951ccebafb40f3b8f0beb28fbaf745431c14a17c497\n",
            "  Building wheel for voluptuous (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for voluptuous: filename=voluptuous-0.11.7-cp36-none-any.whl size=28749 sha256=37b30d8ae37b0bc710c31f3e7d7bce21dd544f3c9391a4337c0c54a53d8c79d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/e3/d0/a2d476b9cd09b8f5979789e0aaf07119726a3cfb19ee67aa1e\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34546 sha256=975fe7da69b3f80c8378a36579fc829d53b06ec92e3989cde24fb8c532137b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
            "  Building wheel for dpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dpath: filename=dpath-2.0.1-cp36-none-any.whl size=15139 sha256=34337a800779381a55ada74d02fda9d5218634acd6d5f895f3ccda394f2260c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/0b/f5/0c40bd93ea28c6dd6a302f2861adc330e9cf3fe99ebfefe797\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=2c76023379f1728dbf40cf8f23abb6b307e0d5384e5b13eebef83a3f9ca9fc44\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nanotime: filename=nanotime-0.5.2-cp36-none-any.whl size=2442 sha256=f06ac22365c6f0b71b7a32472808e6af12738db0ed6117e47b6d63f64580e358\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/99/17/7135f635215e1f61e906295afd11f4f791cfe4ab45f3bfdca2\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=7b7e085323d79630c43ef1a81e953439332ffa37df9f8b90dda3dfb5c0ac058e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.3.2-cp36-none-any.whl size=18867 sha256=eb457758bd539d7b76afed617f5d48a471c1f101a956f22134e500e2373abe11\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/3c/2d28c8ac56cda265d0c16ca129f50e5c3526f49a7fbe224cd9\n",
            "  Building wheel for flufl.lock (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flufl.lock: filename=flufl.lock-3.2-cp36-none-any.whl size=19930 sha256=db5488b1b16fa5220534bee04ead16cb3e21be98d60038b5116b509430e3c911\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/51/d7/f65a7b7f37da7594f7021b122fe677187667ad21f1171d2514\n",
            "  Building wheel for atpublic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atpublic: filename=atpublic-1.0-cp36-none-any.whl size=4505 sha256=41d1b1054770ebd3223392cb497d68a2865220a7b43ad11afc2fda9558efec36\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/5d/fb4b06bb9bb028e49b117b9bdb93c9875e751ff52f6b08aa27\n",
            "Successfully built funcy jsonpath-ng treelib voluptuous configobj dpath networkx nanotime PyYAML pygtrie flufl.lock atpublic\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: alchemy 20.4 has requirement requests==2.22.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: shortuuid, funcy, smmap, gitdb, gitpython, ply, jsonpath-ng, tqdm, distro, treelib, grandalf, voluptuous, configobj, dpath, networkx, zc.lockfile, nanotime, PyYAML, texttable, appdirs, pygtrie, flatten-json, pathspec, atpublic, flufl.lock, python-dateutil, ruamel.yaml.clib, ruamel.yaml, colorama, dvc, cryptography, pyOpenSSL, pydrive2, deprecation, crc32c, tensorboardX, catalyst, alchemy\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "Successfully installed PyYAML-5.3.1 alchemy-20.4 appdirs-1.4.4 atpublic-1.0 catalyst-20.5.1 colorama-0.4.3 configobj-5.0.6 crc32c-2.0 cryptography-2.9.2 deprecation-2.1.0 distro-1.5.0 dpath-2.0.1 dvc-0.93.0 flatten-json-0.1.7 flufl.lock-3.2 funcy-1.14 gitdb-4.0.5 gitpython-3.1.3 grandalf-0.6 jsonpath-ng-1.5.1 nanotime-0.5.2 networkx-2.3 pathspec-0.8.0 ply-3.11 pyOpenSSL-19.1.0 pydrive2-1.4.9 pygtrie-2.3.2 python-dateutil-2.8.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 shortuuid-1.0.1 smmap-3.0.4 tensorboardX-2.0 texttable-1.6.2 tqdm-4.46.0 treelib-1.6.1 voluptuous-0.11.7 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0FNZ-PyZgK3",
        "colab_type": "code",
        "outputId": "ae4d826d-8ed9-488b-d3c6-6ff18757c150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "! dvc pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r!\rIf DVC froze, see `hardlink_lock` in <\u001b[36mman.dvc.org/config#core\u001b[39m>\r                                                                        \r\rQuerying cache in /content/.dvc/cache:   0% 0.00/6.00 [00:00<?, ?file/s]\rQuerying cache in /content/.dvc/cache:   0% 0.00/6.00 [00:00<?, ?file/s]\r                                                                        \r\r!\rEstimating size of cache in 'gdrive://1fX3XdpFjdrNbc2QE0.00 [00:00,     ?file/s]Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=710796635688-iivsgbgsb6uv1fap6635dhvuei09o66c.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n",
            "\n",
            "Enter verification code: \u001b[0m4/0QHexgxctuhVU3BlFYrcA9i7goQyaSregOfBuvXftMBtB6oXyNI1800\n",
            "Authentication successful.\n",
            "Downloading data/processed/MFCC_PREPARE.npy                            ... 569MB\n",
            "!\u001b[A\n",
            "Downloading data/processed/Data_path.csv                              ... 1.04MB\u001b[A\n",
            "\n",
            "!\u001b[A\u001b[A\n",
            "\n",
            "Downloading data/interim/CREMA_df.csv                                  ... 480kB\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "!\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading data/interim/TESS_df.csv                                   ... 474kB\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "!\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading data/interim/RAV_df.csv                                    ... 174kB\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "!\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading data/interim/SAVEE_df.csv                                 ... 41.3kB\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\n",
            "                                                                                \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6 added\n",
            "\u001b[0m\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNKvUUOnYQoa",
        "colab_type": "code",
        "outputId": "cad06c57-b7ec-43bb-d249-a9e1a5ec03d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#import torchvision\n",
        "# from models.resnet import resnet50\n",
        "from metrics.auc import AUCCallback\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.utils import set_global_seed, prepare_cudnn\n",
        "from catalyst.dl.callbacks import AccuracyCallback, PrecisionRecallF1ScoreCallback, VerboseLogger, ConfusionMatrixCallback\n",
        "\n",
        "# Other  \n",
        "from tqdm import tqdm, tqdm_pandas\n",
        "import scipy\n",
        "from scipy.stats import skew\n",
        "import librosa.display\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import glob \n",
        "import os\n",
        "import sys\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import warnings\n",
        "# ignore warnings \n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning:\n",
            "\n",
            "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLme6pdv3h5F",
        "colab_type": "text"
      },
      "source": [
        "Я использую 4 датасета, а именно:\n",
        "\n",
        "    1)SAVEE dataset\n",
        "        Этот набор данных только из мужчин и имеет очень высокое качество \n",
        "        звука. Поскольку на записи только мужчины, это приведет к некоторому \n",
        "        дисбалансу, было бы целесообразно дополнить другие наборы данных \n",
        "        женскими голосами.\n",
        "\n",
        "    2)RAVDESS dataset\n",
        "      Является одним из наиболее распространенных наборов данных, используемых  \n",
        "      для распознавания эмоций другими. Он мне очень понравился из-за его \n",
        "      качества выступающих, хорошей записи, и в нем 24 актера разных полов. \n",
        "\n",
        "    3)TESS dataset\n",
        "        Основан только на двух спикерах, молодой женщине и пожилой женщине. \n",
        "        Надеюсь, что это сбалансирует доминирующих мужчин-спикеров из SAVEE.\n",
        "\n",
        "\n",
        "    4)CREMA-D dataset\n",
        "        Это очень большой набор данных у которого есть большое разнообразие     \n",
        "        разных записей, по-видимому, взятых из фильмов. Спикеры разных \n",
        "        национальностей, а значит лучшее мы имеем возможность тестировать\n",
        "        выявлекние эмоций вне рамок языка.\n",
        "\n",
        "\n",
        "Все 4 набора данных являются хорошими наборами данных. Чтобы дать моей модели возможность хорошо работать с новыми наборами данных, я объединяю эти четыре датасета в один. Создав шум и объединив 4 различных набора данных, связанных между собой только идеей создать датасет с эмоциями, я надеюсь найти реальные отличительные характеристики для выявления эмоций."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIiT5zROYQoi",
        "colab_type": "code",
        "outputId": "6bc16e6c-dcf6-4311-8d8b-e6655546ad1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import pandas as pd\n",
        "ref = pd.read_csv(\"data/processed/Data_path.csv\")\n",
        "print(ref.labels.value_counts())\n",
        "ref.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "female_fear       1096\n",
            "female_happy      1096\n",
            "female_angry      1096\n",
            "female_disgust    1096\n",
            "female_sad        1096\n",
            "female_neutral    1056\n",
            "male_neutral       839\n",
            "male_fear          827\n",
            "male_angry         827\n",
            "male_happy         827\n",
            "male_disgust       827\n",
            "male_sad           827\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>source</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male_disgust</td>\n",
              "      <td>SAVEE</td>\n",
              "      <td>../data/raw/surrey-audiovisual-expressed-emoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>male_disgust</td>\n",
              "      <td>SAVEE</td>\n",
              "      <td>../data/raw/surrey-audiovisual-expressed-emoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male_sad</td>\n",
              "      <td>SAVEE</td>\n",
              "      <td>../data/raw/surrey-audiovisual-expressed-emoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male_neutral</td>\n",
              "      <td>SAVEE</td>\n",
              "      <td>../data/raw/surrey-audiovisual-expressed-emoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male_fear</td>\n",
              "      <td>SAVEE</td>\n",
              "      <td>../data/raw/surrey-audiovisual-expressed-emoti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         labels source                                               path\n",
              "0  male_disgust  SAVEE  ../data/raw/surrey-audiovisual-expressed-emoti...\n",
              "1  male_disgust  SAVEE  ../data/raw/surrey-audiovisual-expressed-emoti...\n",
              "2      male_sad  SAVEE  ../data/raw/surrey-audiovisual-expressed-emoti...\n",
              "3  male_neutral  SAVEE  ../data/raw/surrey-audiovisual-expressed-emoti...\n",
              "4     male_fear  SAVEE  ../data/raw/surrey-audiovisual-expressed-emoti..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrHMXepDYQom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "1. Data Augmentation method   \n",
        "'''\n",
        "def speedNpitch(data):\n",
        "    \"\"\"\n",
        "    Speed and Pitch Tuning.\n",
        "    \"\"\"\n",
        "    # you can change low and high here\n",
        "    length_change = np.random.uniform(low=0.8, high = 1)\n",
        "    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n",
        "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
        "    minlen = min(data.shape[0], tmp.shape[0])\n",
        "    data *= 0\n",
        "    data[0:minlen] = tmp[0:minlen]\n",
        "    return data\n",
        "\n",
        "'''\n",
        "2. Extracting the MFCC feature as an image (Matrix format).  \n",
        "'''\n",
        "def feature_extraction(df, n, aug, mfcc_b):\n",
        "    X = np.empty(shape=(df.shape[0], n, 216, 1))\n",
        "    input_length = sampling_rate * audio_duration\n",
        "    \n",
        "    cnt = 0\n",
        "    for fname in tqdm(df.path):\n",
        "        file_path = fname\n",
        "        data, _ = librosa.load(file_path, sr=sampling_rate\n",
        "                               ,res_type=\"kaiser_fast\"\n",
        "                               ,duration=2.5\n",
        "                               ,offset=0.5\n",
        "                              )\n",
        "\n",
        "        # Random offset / Padding\n",
        "        if len(data) > input_length:\n",
        "            max_offset = len(data) - input_length\n",
        "            offset = np.random.randint(max_offset)\n",
        "            data = data[offset:(input_length+offset)]\n",
        "        else:\n",
        "            if input_length > len(data):\n",
        "                max_offset = input_length - len(data)\n",
        "                offset = np.random.randint(max_offset)\n",
        "            else:\n",
        "                offset = 0\n",
        "            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n",
        "\n",
        "        # Augmentation? \n",
        "        if aug == 1:\n",
        "            data = speedNpitch(data)\n",
        "        \n",
        "        # which feature?\n",
        "\n",
        "        if mfcc_b == 1:\n",
        "            # MFCC extraction \n",
        "            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
        "            MFCC = np.expand_dims(MFCC, axis=-1)\n",
        "            X[cnt,] = MFCC\n",
        "            \n",
        "        else:\n",
        "            # Log-melspectogram\n",
        "            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n",
        "            logspec = librosa.amplitude_to_db(melspec)\n",
        "            logspec = np.expand_dims(logspec, axis=-1)\n",
        "            X[cnt,] = logspec\n",
        "            \n",
        "            \n",
        "        cnt += 1\n",
        "    \n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heJZjlXMYQor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from src.features.build_features import feature_extraction\n",
        "# sampling_rate=44100\n",
        "# audio_duration=2.5\n",
        "# n_mfcc = 30\n",
        "# mfcc1 = feature_extraction(df= ref, n_mfcc= n_mfcc, aug = 0, sampling_rate= sampling_rate, audio_duration= audio_duration)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7dPI-KDYQov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save('../data/processed/MFCC_PREPARE.npy', mfcc)\n",
        "# mfcc = np.load('data/processed/.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zvENiGYQoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split between train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(mfcc,\n",
        "                                                    ref.labels,\n",
        "                                                    test_size=0.25,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=8\n",
        "                                                   )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_REXCIQf3Ucv",
        "colab_type": "code",
        "outputId": "315816fc-7984-4ad1-b079-c9a3f314a4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2878, 30, 216, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgSe-6b9YQo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = lb.fit_transform(y_train) # to_categorical\n",
        "y_test = lb.fit_transform(y_test) # to_categorical\n",
        "\n",
        "# Normalization as per the standard NN process\n",
        "# mean = np.mean(X_train, axis=0)\n",
        "# std = np.std(X_train, axis=0)\n",
        "\n",
        "# X_train = (X_train - mean)/std\n",
        "# X_test = (X_test - mean)/std\n",
        "\n",
        "#! Normalization as per the standard NN process\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "def fit_X_scaler(X_train):\n",
        "    \"\"\"fit StandardScaler，and return StandardScaler object\n",
        "    \"\"\"\n",
        "    sc = StandardScaler()\n",
        "    for _, clips in enumerate(X_train):\n",
        "        data_i_truncated = np.squeeze(clips)\n",
        "        sc.partial_fit(data_i_truncated)\n",
        "    return sc\n",
        "\n",
        "def get_X_scaled(X_train, scaler=None):\n",
        "    \"\"\"apply normlization\n",
        "    \"\"\"\n",
        "    X_train_new = np.zeros(X_train.shape)\n",
        "    for indx, clips in enumerate(X_train):\n",
        "        data_i_truncated = np.squeeze(clips)\n",
        "        if scaler is not None:  # normlize\n",
        "            data_i_truncated = scaler.transform(data_i_truncated)\n",
        "        X_train[indx, :, :, 0] = data_i_truncated\n",
        "    return X_train\n",
        "\n",
        "sc = fit_X_scaler(X_train)\n",
        "X_train = get_X_scaled(X_train, sc)\n",
        "X_test = get_X_scaled(X_test, sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdHKrbkGY3tm",
        "colab_type": "code",
        "outputId": "aa5bff97-a1cf-4bb9-b2a3-9a33ad762b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "classes_names = list(lb.classes_)\n",
        "dict_classes_names = { i : classes_names[i] for i in range(0, len(classes_names) ) }\n",
        "dict_classes_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'female_angry',\n",
              " 1: 'female_disgust',\n",
              " 2: 'female_fear',\n",
              " 3: 'female_happy',\n",
              " 4: 'female_neutral',\n",
              " 5: 'female_sad',\n",
              " 6: 'male_angry',\n",
              " 7: 'male_disgust',\n",
              " 8: 'male_fear',\n",
              " 9: 'male_happy',\n",
              " 10: 'male_neutral',\n",
              " 11: 'male_sad'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnjI14pqYQpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = resnet50(pretrained=False, progress=True, num_classes=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6E_Moqj8Pio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torchvision.models.resnet50(pretrained=True,progress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChQfSNGc8lD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Изменение количества выходных классов \n",
        "n_class = 12\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, n_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqGe5zTx8_WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Изменение количества входных слоёв\n",
        "model.conv1 = torch.nn.Conv2d(30, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMN-TuT093v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX2QZyGZYQpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6RztAlDYQpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
        "featuresTrain = torch.FloatTensor(X_train[0:-1])\n",
        "targetsTrain = torch.from_numpy(y_train[0:-1]).type(torch.LongTensor) # data type is long\n",
        "\n",
        "# create feature and targets tensor for test set.\n",
        "featuresTest = torch.FloatTensor(X_test[0:-1])\n",
        "targetsTest = torch.from_numpy(y_test[0:-1]).type(torch.LongTensor) # data type is long\n",
        "\n",
        "trainSet = TensorDataset(featuresTrain,targetsTrain)\n",
        "validSet = TensorDataset(featuresTest,targetsTest)\n",
        "\n",
        "# data loader\n",
        "train_loader = DataLoader(trainSet, batch_size = BATCH_SIZE, shuffle = True)\n",
        "valid_loader = DataLoader(validSet, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K0Q_shDYQpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWUVsujkYQpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Init catalyst components\n",
        "runner = SupervisedRunner(device=device)\n",
        "loaders = {'train': train_loader, 'valid': valid_loader}\n",
        "logdir = 'data/logs/1'\n",
        "callbacks = [\n",
        "             AUCCallback(num_classes = 12, class_names= classes_names),\n",
        "             AccuracyCallback(),\n",
        "             ConfusionMatrixCallback(num_classes = 12, class_names= classes_names),\n",
        "\n",
        "    #AUCCallback(num_classes = 14),\n",
        "    # VerboseLogger(),\n",
        "    # PrecisionRecallF1ScoreCallback(num_classes = 14),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvmkz2tZ4S94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir data/logs/1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfJa0YxYQpS",
        "colab_type": "code",
        "outputId": "e1f1602d-317e-4f62-a67c-8333ac3658f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "runner.train(\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        loaders=loaders,\n",
        "        callbacks=callbacks,\n",
        "        logdir=logdir,\n",
        "        num_epochs=120,\n",
        "        verbose=True,        \n",
        "    )  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1/120 * Epoch (train):   0% 0/540 [00:00<?, ?it/s]\u001b[A\n",
            "1/120 * Epoch (train):   0% 0/540 [00:00<?, ?it/s, accuracy01=0.188, loss=2.335]\u001b[A\n",
            "1/120 * Epoch (train):   0% 1/540 [00:00<01:23,  6.44it/s, accuracy01=0.188, loss=2.335]\u001b[A\n",
            "1/120 * Epoch (train):   0% 1/540 [00:00<01:23,  6.44it/s, accuracy01=0.562, loss=1.580]\u001b[A\n",
            "1/120 * Epoch (train):   0% 2/540 [00:00<01:24,  6.34it/s, accuracy01=0.562, loss=1.580]\u001b[A\n",
            "1/120 * Epoch (train):   0% 2/540 [00:00<01:24,  6.34it/s, accuracy01=0.375, loss=1.904]\u001b[A\n",
            "1/120 * Epoch (train):   1% 3/540 [00:00<01:22,  6.47it/s, accuracy01=0.375, loss=1.904]\u001b[A\n",
            "1/120 * Epoch (train):   1% 3/540 [00:00<01:22,  6.47it/s, accuracy01=0.250, loss=2.219]\u001b[A\n",
            "1/120 * Epoch (train):   1% 4/540 [00:00<01:20,  6.63it/s, accuracy01=0.250, loss=2.219]\u001b[A\n",
            "1/120 * Epoch (train):   1% 4/540 [00:00<01:20,  6.63it/s, accuracy01=0.188, loss=2.265]\u001b[A\n",
            "1/120 * Epoch (train):   1% 5/540 [00:00<01:20,  6.68it/s, accuracy01=0.188, loss=2.265]\u001b[A\n",
            "1/120 * Epoch (train):   1% 5/540 [00:00<01:20,  6.68it/s, accuracy01=0.500, loss=1.743]\u001b[A\n",
            "1/120 * Epoch (train):   1% 6/540 [00:00<01:17,  6.85it/s, accuracy01=0.500, loss=1.743]\u001b[A\n",
            "1/120 * Epoch (train):   1% 6/540 [00:01<01:17,  6.85it/s, accuracy01=0.438, loss=1.913]\u001b[A\n",
            "1/120 * Epoch (train):   1% 7/540 [00:01<01:15,  7.07it/s, accuracy01=0.438, loss=1.913]\u001b[A\n",
            "1/120 * Epoch (train):   1% 7/540 [00:01<01:15,  7.07it/s, accuracy01=0.312, loss=1.708]\u001b[A\n",
            "1/120 * Epoch (train):   1% 8/540 [00:01<01:12,  7.30it/s, accuracy01=0.312, loss=1.708]\u001b[A\n",
            "1/120 * Epoch (train):   1% 8/540 [00:01<01:12,  7.30it/s, accuracy01=0.188, loss=1.948]\u001b[A\n",
            "1/120 * Epoch (train):   2% 9/540 [00:01<01:10,  7.50it/s, accuracy01=0.188, loss=1.948]\u001b[A\n",
            "1/120 * Epoch (train):   2% 9/540 [00:01<01:10,  7.50it/s, accuracy01=0.062, loss=2.263]\u001b[A\n",
            "1/120 * Epoch (train):   2% 10/540 [00:01<01:09,  7.68it/s, accuracy01=0.062, loss=2.263]\u001b[A\n",
            "1/120 * Epoch (train):   2% 10/540 [00:01<01:09,  7.68it/s, accuracy01=0.250, loss=1.760]\u001b[A\n",
            "1/120 * Epoch (train):   2% 11/540 [00:01<01:07,  7.79it/s, accuracy01=0.250, loss=1.760]\u001b[A\n",
            "1/120 * Epoch (train):   2% 11/540 [00:01<01:07,  7.79it/s, accuracy01=0.188, loss=2.341]\u001b[A\n",
            "1/120 * Epoch (train):   2% 12/540 [00:01<01:06,  7.88it/s, accuracy01=0.188, loss=2.341]\u001b[A\n",
            "1/120 * Epoch (train):   2% 12/540 [00:01<01:06,  7.88it/s, accuracy01=0.438, loss=1.940]\u001b[A\n",
            "1/120 * Epoch (train):   2% 13/540 [00:01<01:06,  7.95it/s, accuracy01=0.438, loss=1.940]\u001b[A\n",
            "1/120 * Epoch (train):   2% 13/540 [00:01<01:06,  7.95it/s, accuracy01=0.188, loss=2.318]\u001b[A\n",
            "1/120 * Epoch (train):   3% 14/540 [00:01<01:07,  7.82it/s, accuracy01=0.188, loss=2.318]\u001b[A\n",
            "1/120 * Epoch (train):   3% 14/540 [00:02<01:07,  7.82it/s, accuracy01=0.188, loss=2.492]\u001b[A\n",
            "1/120 * Epoch (train):   3% 15/540 [00:02<01:05,  7.97it/s, accuracy01=0.188, loss=2.492]\u001b[A\n",
            "1/120 * Epoch (train):   3% 15/540 [00:02<01:05,  7.97it/s, accuracy01=0.188, loss=2.251]\u001b[A\n",
            "1/120 * Epoch (train):   3% 16/540 [00:02<01:05,  8.02it/s, accuracy01=0.188, loss=2.251]\u001b[A\n",
            "1/120 * Epoch (train):   3% 16/540 [00:02<01:05,  8.02it/s, accuracy01=0.125, loss=2.642]\u001b[A\n",
            "1/120 * Epoch (train):   3% 17/540 [00:02<01:05,  8.01it/s, accuracy01=0.125, loss=2.642]\u001b[A\n",
            "1/120 * Epoch (train):   3% 17/540 [00:02<01:05,  8.01it/s, accuracy01=0.500, loss=1.455]\u001b[A\n",
            "1/120 * Epoch (train):   3% 18/540 [00:02<01:04,  8.12it/s, accuracy01=0.500, loss=1.455]\u001b[A\n",
            "1/120 * Epoch (train):   3% 18/540 [00:02<01:04,  8.12it/s, accuracy01=0.188, loss=2.177]\u001b[A\n",
            "1/120 * Epoch (train):   4% 19/540 [00:02<01:04,  8.14it/s, accuracy01=0.188, loss=2.177]\u001b[A\n",
            "1/120 * Epoch (train):   4% 19/540 [00:02<01:04,  8.14it/s, accuracy01=0.250, loss=2.033]\u001b[A\n",
            "1/120 * Epoch (train):   4% 20/540 [00:02<01:04,  8.11it/s, accuracy01=0.250, loss=2.033]\u001b[A\n",
            "1/120 * Epoch (train):   4% 20/540 [00:02<01:04,  8.11it/s, accuracy01=0.438, loss=1.773]\u001b[A\n",
            "1/120 * Epoch (train):   4% 21/540 [00:02<01:04,  8.07it/s, accuracy01=0.438, loss=1.773]\u001b[A\n",
            "1/120 * Epoch (train):   4% 21/540 [00:02<01:04,  8.07it/s, accuracy01=0.312, loss=2.134]\u001b[A\n",
            "1/120 * Epoch (train):   4% 22/540 [00:02<01:04,  8.04it/s, accuracy01=0.312, loss=2.134]\u001b[A\n",
            "1/120 * Epoch (train):   4% 22/540 [00:03<01:04,  8.04it/s, accuracy01=0.125, loss=2.313]\u001b[A\n",
            "1/120 * Epoch (train):   4% 23/540 [00:03<01:04,  7.96it/s, accuracy01=0.125, loss=2.313]\u001b[A\n",
            "1/120 * Epoch (train):   4% 23/540 [00:03<01:04,  7.96it/s, accuracy01=0.438, loss=1.690]\u001b[A\n",
            "1/120 * Epoch (train):   4% 24/540 [00:03<01:04,  8.03it/s, accuracy01=0.438, loss=1.690]\u001b[A\n",
            "1/120 * Epoch (train):   4% 24/540 [00:03<01:04,  8.03it/s, accuracy01=0.250, loss=1.890]\u001b[A\n",
            "1/120 * Epoch (train):   5% 25/540 [00:03<01:04,  8.04it/s, accuracy01=0.250, loss=1.890]\u001b[A\n",
            "1/120 * Epoch (train):   5% 25/540 [00:03<01:04,  8.04it/s, accuracy01=0.312, loss=1.841]\u001b[A\n",
            "1/120 * Epoch (train):   5% 26/540 [00:03<01:03,  8.06it/s, accuracy01=0.312, loss=1.841]\u001b[A\n",
            "1/120 * Epoch (train):   5% 26/540 [00:03<01:03,  8.06it/s, accuracy01=0.500, loss=1.512]\u001b[A\n",
            "\n",
            "\u001b[AEarly exiting\n",
            "1/120 * Epoch (train):  20% 106/540 [00:31<00:48,  8.95it/s, accuracy01=0.375, loss=1.728]\n",
            "1/120 * Epoch (train):   5% 27/540 [00:03<01:03,  8.08it/s, accuracy01=0.500, loss=1.512]\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFiNip1Eu4rL",
        "colab_type": "code",
        "outputId": "c498a0da-6a77-4520-808c-01e530f03441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "! zip -r logs.zip data/logs/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: data/logs/ (stored 0%)\n",
            "  adding: data/logs/0/ (stored 0%)\n",
            "  adding: data/logs/0/checkpoints/ (stored 0%)\n",
            "  adding: data/logs/0/checkpoints/_metrics.json (deflated 76%)\n",
            "  adding: data/logs/0/checkpoints/train.7.pth (deflated 17%)\n",
            "  adding: data/logs/0/checkpoints/last.pth (deflated 16%)\n",
            "  adding: data/logs/0/checkpoints/last_full.pth (deflated 28%)\n",
            "  adding: data/logs/0/checkpoints/train.7_full.pth (deflated 28%)\n",
            "  adding: data/logs/0/checkpoints/best_full.pth (deflated 28%)\n",
            "  adding: data/logs/0/checkpoints/best.pth (deflated 17%)\n",
            "  adding: data/logs/0/_base_log/ (stored 0%)\n",
            "  adding: data/logs/0/_base_log/events.out.tfevents.1590755877.70706919b3ea.120.0 (deflated 68%)\n",
            "  adding: data/logs/0/valid_log/ (stored 0%)\n",
            "  adding: data/logs/0/valid_log/events.out.tfevents.1590755973.70706919b3ea.120.2 (deflated 31%)\n",
            "  adding: data/logs/0/train_log/ (stored 0%)\n",
            "  adding: data/logs/0/train_log/events.out.tfevents.1590755877.70706919b3ea.120.1 (deflated 47%)\n",
            "  adding: data/logs/0/log.txt (deflated 82%)\n",
            "  adding: data/logs/.ipynb_checkpoints/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWBpjfORyRbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}